<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>title</title>
      <link href="/2025/07/02/12312-312-43415/"/>
      <url>/2025/07/02/12312-312-43415/</url>
      
        <content type="html"><![CDATA[<p>阿萨德阿萨德 12 请问请问爱学习卅阿是DASASDF ASF ASDF ASDF ASD ASDF </p><p>ASDA sdfasdf asdf asdf asdf</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>title</title>
      <link href="/2025/07/02/12312-312/"/>
      <url>/2025/07/02/12312-312/</url>
      
        <content type="html"><![CDATA[<p>qwfAEDVSxc</p><p>dasd asd asd as das dasd as das d</p>]]></content>
      
      
      <categories>
          
          <category> 建站测试  </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>test</title>
      <link href="/2025/07/02/test-1/"/>
      <url>/2025/07/02/test-1/</url>
      
        <content type="html"><![CDATA[<h1 id="核心代码说明"><a href="#核心代码说明" class="headerlink" title="核心代码说明"></a>核心代码说明</h1><h2 id="Pytorch-Unet"><a href="#Pytorch-Unet" class="headerlink" title="Pytorch-Unet"></a>Pytorch-Unet</h2><p>本项目提供了四种语义分割模型的实现与对比，包括 <strong>UNET</strong>、<strong>BBSNET</strong>、<strong>UCNET</strong> 及改进版 <strong>UNET</strong>。支持在 RGB-D 图像数据集（如 NYUv2）上运行，并输出分割结果。</p><hr><h2 id="1-目录结构"><a href="#1-目录结构" class="headerlink" title="1. 目录结构"></a>1. 目录结构</h2><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">├── Pytorch-UNet # 原始 UNET 实现 + 个人修改</span><br><span class="line">├── Unet-for-rgbd-sod # RGB-D UNET 训练  +  增强版 UNET</span><br><span class="line">├── BBS-Net # BBSNET 官方实现 + 个人修改</span><br><span class="line">├── UCNet # UCNET 官方实现  + 个人修改</span><br><span class="line">├── data # 数据集存放路径（需自行准备）</span><br><span class="line">├── results # 输出结果保存路径</span><br><span class="line">└── readme.md # 本说明文件</span><br></pre></td></tr></tbody></table></figure><hr><h2 id="2-环境依赖"><a href="#2-环境依赖" class="headerlink" title="2. 环境依赖"></a>2. 环境依赖</h2><figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建并激活 Python 3.8 虚拟环境</span></span><br><span class="line">sudo apt update &amp;&amp; sudo apt install python3<span class="number">.8</span>-venv</span><br><span class="line">python3<span class="number">.8</span> -m venv seg_env</span><br><span class="line">source seg_env/<span class="built_in">bin</span>/activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装基础依赖</span></span><br><span class="line">pip install --upgrade pip</span><br><span class="line">pip install torch==<span class="number">1.12</span><span class="number">.1</span>+cu113 torchvision==<span class="number">0.13</span><span class="number">.1</span>+cu113 \</span><br><span class="line">            numpy opencv-python matplotlib pillow</span><br></pre></td></tr></tbody></table></figure><p>确保安装以下 Python 库：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch torchvision numpy opencv-python matplotlib pillow</span><br></pre></td></tr></tbody></table></figure><p><strong>特殊依赖</strong>：</p><ul><li><strong>PyTorch</strong> 版本需与模型代码兼容（建议使用与作者一致的版本，如 <code>torch==1.7.0</code>）</li><li>部分模型可能依赖 <code>scipy</code> 或 <code>tifffile</code>，可通过以下命令安装：</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scipy tifffile</span><br></pre></td></tr></tbody></table></figure><hr><p><strong>环境要求</strong>：Ubuntu Linux + Python 3.8 + NVIDIA RTX 4090</p><h2 id="3-数据集准备"><a href="#3-数据集准备" class="headerlink" title="3. 数据集准备"></a>3. 数据集准备</h2><h3 id="3-1-下载数据集"><a href="#3-1-下载数据集" class="headerlink" title="3.1 下载数据集"></a>3.1 下载数据集</h3><p>以 <strong>NYUv2</strong> 为例：</p><ol><li>下载 NYUv2 Depth V2</li><li>解压后将 <code>images</code> 和 <code>masks</code> 文件夹放入 <code>data/</code> 目录</li><li>其他 RGBD  图片下载按照对应文件夹中的配置即可</li></ol><blockquote><p>注意要修改对应 train 中数据集的位置, 以确保能够正确导入数据</p></blockquote><h3 id="3-2-数据格式要求"><a href="#3-2-数据格式要求" class="headerlink" title="3.2 数据格式要求"></a>3.2 数据格式要求</h3><ul><li>输入图像：RGB 格式（H×W×3）</li><li>深度图：单通道灰度图（H×W×1）</li><li>mask图：类别标签（H×W×1，整数类型）</li></ul><hr><h2 id="4-模型运行指南"><a href="#4-模型运行指南" class="headerlink" title="4. 模型运行指南"></a>4. 模型运行指南</h2><h3 id="4-1-原始-UNET-Pytorch-UNet"><a href="#4-1-原始-UNET-Pytorch-UNet" class="headerlink" title="4.1 原始 UNET (Pytorch-UNet)"></a>4.1 原始 UNET (<code>Pytorch-UNet</code>)</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd Pytorch-UNet</span><br><span class="line">python train.py --dataset nyuv2 --batch-size 8 --epochs 50</span><br></pre></td></tr></tbody></table></figure><ul><li><p>输出结果保存在 <code>Pytorch-UNet/results/</code> 目录</p></li><li><p>可视化训练过程：<code>tensorboard --logdir=runs</code></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python train.py \</span><br><span class="line">  --dataset nyuv2 \</span><br><span class="line">  --batch-size 8 \</span><br><span class="line">  --epochs 50 \</span><br><span class="line">  --scale 0.5 \          # 图像缩放因子</span><br><span class="line">  --classes 2 \          # 类别数</span><br><span class="line">  --amp                  # 可选：启用混合精度训练</span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="4-2-RGB-D-增强版-UNET-Unet-for-rgbd-sod"><a href="#4-2-RGB-D-增强版-UNET-Unet-for-rgbd-sod" class="headerlink" title="4.2 RGB-D 增强版 UNET (Unet-for-rgbd-sod)"></a>4.2 RGB-D 增强版 UNET (<code>Unet-for-rgbd-sod</code>)</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd Unet-for-rgbd-sod</span><br><span class="line">python main.py --mode train --data-root data/nyuv2</span><br></pre></td></tr></tbody></table></figure><ul><li>支持 RGB-D 融合输入，需确保深度图与图像对齐</li><li>修改 <code>config.py</code> 中的 <code>depth_weight</code> 参数调整深度图权重</li><li>其中包含消融实验和改进后的 UNET训练代码, 配置同 UNET</li></ul><h3 id="4-3-BBSNET-BBS-Net"><a href="#4-3-BBSNET-BBS-Net" class="headerlink" title="4.3 BBSNET (BBS-Net)"></a>4.3 BBSNET (<code>BBS-Net</code>)</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-BBS_dataset\ </span><br><span class="line">  -RGBD_for_train\  </span><br><span class="line">  -RGBD_for_test\</span><br><span class="line">  -test_in_train\</span><br><span class="line">-BBSNet</span><br><span class="line">  -models\</span><br><span class="line">  -model_pths\</span><br><span class="line">     -BBSNet.pth</span><br><span class="line">  ...</span><br></pre></td></tr></tbody></table></figure><ul><li>模型训练</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd BBS-Net</span><br><span class="line">python BBSNet_train.py --batchsize 10 --gpu_id 0</span><br></pre></td></tr></tbody></table></figure><ul><li>模型测试</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python BBSNet_test.py --gpu_id 0 </span><br></pre></td></tr></tbody></table></figure><ul><li>sota 模型下载 :  [code: dwcp]  <a href="https://pan.baidu.com/s/1Fn-Hvdou4DDWcgeTtx081g?_at_=1748571067778">https://pan.baidu.com/s/1Fn-Hvdou4DDWcgeTtx081g?_at_=1748571067778</a></li><li>输出包含边界感知的分割结果</li></ul><h3 id="4-4-UCNET-UCNet"><a href="#4-4-UCNET-UCNet" class="headerlink" title="4.4 UCNET (UCNet)"></a>4.4 UCNET (<code>UCNet</code>)</h3><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd UCNet</span><br><span class="line">python train.py </span><br></pre></td></tr></tbody></table></figure><ul><li>使用多尺度训练提升精度</li></ul><p>cite:</p><figure class="highlight tex"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings{Zhang2020UCNet,</span><br><span class="line">  title={UC-Net: Uncertainty Inspired RGB-D Saliency Detection via Conditional Variational Autoencoders},</span><br><span class="line">  author={Zhang, Jing and Fan, Deng-Ping and Dai, Yuchao and Anwar, Saeed and Sadat Saleh, Fatemeh and Zhang, Tong and Barnes, Nick},</span><br><span class="line">  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},</span><br><span class="line">  year={2020}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><figure class="highlight tex"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@article{zhang2021uncertainty,</span><br><span class="line">  title={Uncertainty Inspired RGB-D Saliency Detection},</span><br><span class="line">  author={Jing Zhang and Deng-Ping Fan and Yuchao Dai and Saeed Anwar and Fatemeh Saleh and Sadegh Aliakbarian and Nick Barnes},</span><br><span class="line">  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, </span><br><span class="line">  year={2021}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><img src="https://zzhaire-markdown.oss-cn-shanghai.aliyuncs.com/imgs/image-20250701194706995.png" alt="image-20250701194706995"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/07/02/hello-world/"/>
      <url>/2025/07/02/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
